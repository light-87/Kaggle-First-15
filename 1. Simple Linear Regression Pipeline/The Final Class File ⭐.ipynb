{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from yellowbrick.regressor import PredictionError\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "class DataScienceProject:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        # Load data using pandas\n",
    "        data = pd.read_csv(file_path)\n",
    "        return data\n",
    "\n",
    "    def report_missing_values(self, df ):\n",
    "        # Calculate the number of missing values per column\n",
    "        missing_values = df.isnull().sum()\n",
    "        missing_report = pd.DataFrame(missing_values, columns=['missing_values'])\n",
    "        missing_report = missing_report[missing_report['missing_values'] > 0]\n",
    "\n",
    "        # Suggest imputation values\n",
    "        imputation_values = {}\n",
    "        for column in missing_report.index:\n",
    "            if df[column].dtype in ['int64', 'float64']:\n",
    "                skewness = df[column].skew()\n",
    "                if abs(skewness) > 0.5:\n",
    "                    imputation_value = df[column].median()\n",
    "                    imputation_values[column] = ('median', imputation_value)\n",
    "                else:\n",
    "                    imputation_value = df[column].mean()\n",
    "                    imputation_values[column] = ('mean', imputation_value)\n",
    "            else:\n",
    "                imputation_value = df[column].mode()[0]\n",
    "                imputation_values[column] = ('mode', imputation_value)\n",
    "\n",
    "        return imputation_values\n",
    "\n",
    "    def apply_imputations(self, df, imputation_values):\n",
    "        for column, (strategy, value) in imputation_values.items():\n",
    "            if strategy in ['mean', 'median', 'mode']:\n",
    "                df[column].fillna(value, inplace=True)\n",
    "        # print(\"after imp\", df.isna().sum())\n",
    "        return df\n",
    "\n",
    "\n",
    "    def visualize_data(self, data, title_suffix=''):\n",
    "        \"\"\"\n",
    "        Visualizes distributions of numerical and categorical features in the dataset.\n",
    "\n",
    "        Args:\n",
    "        data (DataFrame): The dataset to visualize.\n",
    "        title_suffix (str): A suffix for the plot title to distinguish between original and preprocessed data.\n",
    "        \"\"\"\n",
    "        numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "        # Plot for numerical features\n",
    "        for col in numerical_cols:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.histplot(data[col], kde=True)\n",
    "            plt.title(f'Distribution of {col} {title_suffix}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "\n",
    "        # Plot for categorical features\n",
    "        for col in categorical_cols:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.countplot(x=col, data=data)\n",
    "            plt.title(f'Distribution of {col} {title_suffix}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "\n",
    "    def select_data_within_iqr(self, df, iqr_factor=1.5):\n",
    "        # Select only numerical columns for IQR calculation\n",
    "        numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "        # Calculate IQR for numerical columns\n",
    "        Q1 = df[numerical_cols].quantile(0.25)\n",
    "        Q3 = df[numerical_cols].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Determine bounds for outlier detection\n",
    "        lower_bound = Q1 - (iqr_factor * IQR)\n",
    "        upper_bound = Q3 + (iqr_factor * IQR)\n",
    "\n",
    "        # Create a filter for rows to keep\n",
    "        filter_rows = ((df[numerical_cols] >= lower_bound) & (df[numerical_cols] <= upper_bound)).all(axis=1)\n",
    "\n",
    "        # Apply this filter to the entire DataFrame\n",
    "        filtered_df = df[filter_rows]\n",
    "\n",
    "        return filtered_df\n",
    "\n",
    "    def apply_log_transformation(self, df, target_column,skew_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Applies log transformation to highly skewed columns.\n",
    "\n",
    "        Args:\n",
    "        df (DataFrame): The dataframe containing the data.\n",
    "        skew_threshold (float): The threshold to identify highly skewed columns.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The dataframe with log-transformed columns.\n",
    "        \"\"\"\n",
    "        for column in df.select_dtypes(include=['float64', 'int64']):\n",
    "            if df[column].skew() > skew_threshold and column != target_column :\n",
    "                df['Log_' + column] = np.log1p(df[column])\n",
    "\n",
    "        # print(df.columns)\n",
    "        # print(\"after log\", df.isna().sum())\n",
    "        return df\n",
    "\n",
    "    def encode_categorical_columns(self, df):\n",
    "        \"\"\"\n",
    "        Encodes categorical columns using one-hot encoding and removes the original columns.\n",
    "\n",
    "        Args:\n",
    "        df (DataFrame): The dataframe to process.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: The dataframe with categorical columns one-hot encoded.\n",
    "        \"\"\"\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            # Apply one-hot encoding to each categorical column\n",
    "            dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, data, target_column):\n",
    "        # Report and apply imputations, and handle outliers\n",
    "        imputation_values = self.report_missing_values(data)\n",
    "        data = self.apply_imputations(data, imputation_values)\n",
    "        data = self.encode_categorical_columns(data)\n",
    "        data = self.apply_log_transformation(data, target_column)\n",
    "        data = self.select_data_within_iqr(data)\n",
    "        return data\n",
    "\n",
    "    def train_model(self, training_data, target_column):\n",
    "        # Modify to return X_train, X_test, y_train, y_test for Lasso analysis\n",
    "        X = training_data.drop(target_column, axis=1)\n",
    "        y = training_data[target_column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        return model, X_train, X_test, y_train, y_test\n",
    "\n",
    "    def plot_actual_vs_predicted(self, y_test, y_predict, model_type):\n",
    "        \"\"\"\n",
    "        Plots the actual vs predicted values.\n",
    "\n",
    "        Args:\n",
    "        y_test (array-like): The true values of the target variable.\n",
    "        y_predict (array-like): The predicted values by the model.\n",
    "        model_type (str): Type of the model ('Baseline' or 'Main').\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.title(f\"{model_type} Model: Actual vs Predicted Values\")\n",
    "        x_points = list(range(len(y_test)))\n",
    "        plt.plot(x_points, y_test, label='Actual Values', marker='o')\n",
    "        plt.plot(x_points, y_predict, label='Predicted Values', marker='x')\n",
    "        plt.xlabel('Data Points')\n",
    "        plt.ylabel('Target Variable')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_learning_curve_and_prediction_error(self, model, X_train, X_test, y_train, y_test, model_type):\n",
    "        \"\"\"\n",
    "        Plots the learning curve and prediction error using Yellowbrick.\n",
    "\n",
    "        Args:\n",
    "        model: The trained model.\n",
    "        X_train, X_test, y_train, y_test: Training and testing data.\n",
    "        model_type (str): Type of the model ('Baseline' or 'Main').\n",
    "        \"\"\"\n",
    "        # Learning Curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        lc_viz = LearningCurve(model, cv=5, scoring='r2', n_jobs=4, train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "        lc_viz.fit(X_train, y_train)\n",
    "        lc_viz.set_title(f\"{model_type} Model: Learning Curve\")\n",
    "        lc_viz.show()\n",
    "\n",
    "        # Prediction Error\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        pe_viz = PredictionError(model)\n",
    "        pe_viz.fit(X_train, y_train)\n",
    "        pe_viz.score(X_test, y_test)\n",
    "        pe_viz.set_title(f\"{model_type} Model: Prediction Error\")\n",
    "        pe_viz.show()\n",
    "\n",
    "\n",
    "    def feature_importance_lasso(self, X_train, y_train, X_test, y_test):\n",
    "        # Create and fit the LassoCV model\n",
    "        lasso = LassoCV(cv=5, random_state=0)\n",
    "        lasso.fit(X_train, y_train)\n",
    "\n",
    "        best_alpha = lasso.alpha_\n",
    "        lasso_coef = lasso.coef_\n",
    "        y_pred = lasso.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Plotting feature importances\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        feature_importance = pd.Series(lasso_coef, index=X_train.columns).sort_values()\n",
    "        feature_importance.plot(kind='barh')\n",
    "        plt.title('Feature Importances from Lasso Model')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Best alpha: {best_alpha}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "    def make_prediction(self, model, new_data):\n",
    "        # Make predictions using the trained model\n",
    "        prediction = model.predict(new_data)\n",
    "        return prediction\n",
    "\n",
    "    def train_and_evaluate(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        Train a linear regression model and evaluate it.\n",
    "        \"\"\"\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        return model, mse, r2, mae\n",
    "\n",
    "    def main_pipeline(self, file_path, target_column):\n",
    "        print(\"===== Data Science Project Pipeline =====\")\n",
    "        print(\"[Step 1] Loading and Preprocessing Data\")\n",
    "        data = self.load_data(file_path)\n",
    "\n",
    "        # Visualize original data\n",
    "        self.visualize_data(data, title_suffix='(Original)')\n",
    "\n",
    "        preprocessed_data = self.preprocess_data(data, target_column)\n",
    "\n",
    "        # Visualize preprocessed data\n",
    "        self.visualize_data(preprocessed_data, title_suffix='(Preprocessed)')\n",
    "\n",
    "        # Baseline Model\n",
    "        print(\"\\n[Step 2] Training and Evaluating Baseline Model\")\n",
    "        mse_baseline, r2_baseline, baseline_model, X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline, mae_baseline = self.compare_with_baseline(data, target_column)\n",
    "        y_pred_baseline = baseline_model.predict(X_test_baseline)\n",
    "        self.plot_actual_vs_predicted(y_test_baseline, y_pred_baseline, \"Baseline\")\n",
    "        self.plot_learning_curve_and_prediction_error(baseline_model, X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline, \"Baseline\")\n",
    "\n",
    "        # Main Model\n",
    "        print(\"\\n[Step 3] Training and Evaluating Main Model\")\n",
    "        model, X_train, X_test, y_train, y_test = self.train_model(preprocessed_data, target_column)\n",
    "        _, mse_main, r2_main, mae = self.train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "        y_predict_main = model.predict(X_test)\n",
    "        self.plot_actual_vs_predicted(y_test, y_predict_main, \"Main\")\n",
    "        self.plot_learning_curve_and_prediction_error(model, X_train, X_test, y_train, y_test, \"Main\")\n",
    "\n",
    "        print(\"\\n[Step 4] Performing Lasso Feature Importance Analysis\")\n",
    "        self.feature_importance_lasso(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        print(\"\\n===== Model Comparison Results =====\")\n",
    "        print(\"Baseline Model:\")\n",
    "        print(\"  - MSE: {:.3f}\".format(mse_baseline))\n",
    "        print(\"  - R-squared: {:.3f}\".format(r2_baseline))\n",
    "        print(\"  - MAE: {:.3f}\".format(mae))\n",
    "        print(\"Main Model:\")\n",
    "        print(\"  - MSE: {:.3f}\".format(mse_main))\n",
    "        print(\"  - R-squared: {:.3f}\".format(r2_main))\n",
    "        print(\"  - MAE: {:.3f}\".format(mae_baseline))\n",
    "        print(\"====================================\")\n",
    "\n",
    "        return preprocessed_data\n",
    "\n",
    "    def compare_with_baseline(self, data, target_column):\n",
    "        # Updated to return the model and train/test splits\n",
    "        baseline_data = data.dropna()\n",
    "        X_baseline = baseline_data.drop(target_column, axis=1)\n",
    "        X_baseline = self.encode_categorical_columns(X_baseline)\n",
    "        y_baseline = baseline_data[target_column]\n",
    "        X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline = train_test_split(X_baseline, y_baseline, test_size=0.2, random_state=1)\n",
    "        baseline_model, mse_baseline, r2_baseline, mae_baseline = self.train_and_evaluate(X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline)\n",
    "        return mse_baseline, r2_baseline, baseline_model, X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline, mae_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'path/to/your/data.csv'\n",
    "target_column = 'YourTargetColumn'\n",
    "dsp = DataScienceProject()\n",
    "\n",
    "dsp.main_pipeline(file_path, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e6f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
